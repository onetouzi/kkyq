import csv
import os
import requests
from PIL import Image
from io import BytesIO

# ================= é…ç½®å‚æ•° =================
CSV_FILE_PATH = "book30-listing-test.csv"  # æ›¿æ¢ä¸ºä½ çš„å®é™…CSVæ–‡ä»¶è·¯å¾„ï¼ˆå¦‚G:/work8/kkyq/mode/books.csvï¼‰
SAVE_DIR = "book_dataset/books"    # ç›®æ ‡ä¿å­˜ç›®å½•
MAX_IMAGES = 600                  # åªçˆ¬å–å‰600å¼ 
TIMEOUT = 10                      # å›¾ç‰‡ä¸‹è½½è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰

# ================= åˆ›å»ºä¿å­˜ç›®å½• =================
os.makedirs(SAVE_DIR, exist_ok=True)

# ================= æ ¸å¿ƒçˆ¬å–é€»è¾‘ =================
def crawl_book_covers():
    # 1. è¯»å–CSVæ–‡ä»¶ï¼ˆè‡ªåŠ¨é€‚é…ç¼–ç +é€—å·åˆ†éš”ï¼‰
    book_data = []
    # ä¼˜å…ˆå°è¯•ä¸­æ–‡ç³»ç»Ÿå¸¸è§ç¼–ç ï¼Œå†è¯•UTF-8
    encodings = ["gbk", "gb2312", "utf-8", "utf-8-sig"]
    
    for encoding in encodings:
        try:
            with open(CSV_FILE_PATH, "r", encoding=encoding, newline="") as csvfile:
                # å…³é”®ä¿®æ”¹ï¼šä½¿ç”¨é€—å·åˆ†éš”ç¬¦ï¼ˆæ ‡å‡†CSVï¼‰ï¼Œå¹¶å¤„ç†åŒå¼•å·åŒ…è£¹
                reader = csv.reader(csvfile, delimiter=",", quotechar='"')
                for row in reader:
                    if len(row) >= 4:  # ç¡®ä¿è¡Œæœ‰è¶³å¤Ÿå­—æ®µï¼ˆè‡³å°‘åŒ…å«URLåˆ—ï¼‰
                        filename = row[1].strip()  # ç¬¬äºŒåˆ—ï¼šå›¾ç‰‡æ–‡ä»¶åï¼ˆå¦‚044310073X.jpgï¼‰
                        img_url = row[2].strip()   # ç¬¬ä¸‰åˆ—ï¼šå›¾ç‰‡URLï¼ˆä¹‹å‰æ•°é”™åˆ—ï¼ï¼‰
                        # è¿‡æ»¤ç©ºæ–‡ä»¶å/ç©ºURL
                        if filename and img_url.startswith(("http://", "https://")):
                            book_data.append((filename, img_url))
            print(f"âœ… æˆåŠŸä½¿ç”¨ {encoding} ç¼–ç è¯»å–CSVæ–‡ä»¶")
            break  # ç¼–ç æ­£ç¡®åˆ™è·³å‡ºå¾ªç¯
        except UnicodeDecodeError:
            print(f"âŒ {encoding} ç¼–ç è§£ç å¤±è´¥ï¼Œå°è¯•ä¸‹ä¸€ä¸ªç¼–ç ...")
            continue
        except Exception as e:
            print(f"âŒ è¯»å–CSVå‡ºé”™ï¼š{e}")
            return
    
    if not book_data:
        print("âŒ ERRORï¼šæ‰€æœ‰ç¼–ç éƒ½æ— æ³•è§£æCSVæ–‡ä»¶ï¼Œæˆ–æ–‡ä»¶æ— æœ‰æ•ˆæ•°æ®ï¼")
        return
    
    # 2. é™åˆ¶åªçˆ¬å–å‰600æ¡
    book_data = book_data[:MAX_IMAGES]
    print(f"ğŸ“„ å…±è¯»å–åˆ° {len(book_data)} æ¡æœ‰æ•ˆæ•°æ®ï¼ˆå·²é™åˆ¶å‰{MAX_IMAGES}æ¡ï¼‰ï¼Œå¼€å§‹çˆ¬å–...")
    
    # 3. æ‰¹é‡ä¸‹è½½å›¾ç‰‡
    success_count = 0
    fail_count = 0
    for idx, (filename, img_url) in enumerate(book_data, 1):
        try:
            # å‘é€è¯·æ±‚ä¸‹è½½å›¾ç‰‡ï¼ˆæ·»åŠ è¯·æ±‚å¤´é¿å…è¢«äºšé©¬é€Šæ‹¦æˆªï¼‰
            headers = {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
            }
            response = requests.get(img_url, headers=headers, timeout=TIMEOUT)
            response.raise_for_status()  # æŠ›å‡ºHTTPé”™è¯¯ï¼ˆå¦‚404/500ï¼‰
            
            # éªŒè¯å›¾ç‰‡æœ‰æ•ˆæ€§å¹¶ä¿å­˜
            img = Image.open(BytesIO(response.content))
            # ç»Ÿä¸€è½¬æ¢ä¸ºRGBï¼ˆé¿å…PNGé€æ˜é€šé“/æ ¼å¼é—®é¢˜ï¼‰
            if img.mode != "RGB":
                img = img.convert("RGB")
            save_path = os.path.join(SAVE_DIR, filename)
            img.save(save_path, "JPEG", quality=95)  # ä¿å­˜ä¸ºJPEGï¼Œä¿è¯è´¨é‡
            
            success_count += 1
            print(f"[{idx}/{MAX_IMAGES}] âœ… æˆåŠŸï¼š{filename}")
        
        except requests.exceptions.Timeout:
            fail_count += 1
            print(f"[{idx}/{MAX_IMAGES}] â³ è¶…æ—¶ï¼š{filename} -> {img_url}")
        except requests.exceptions.HTTPError as e:
            fail_count += 1
            print(f"[{idx}/{MAX_IMAGES}] âŒ HTTPé”™è¯¯ï¼š{filename} -> {e}")
        except requests.exceptions.ConnectionError:
            fail_count += 1
            print(f"[{idx}/{MAX_IMAGES}] âŒ è¿æ¥å¤±è´¥ï¼š{filename} -> {img_url}")
        except Exception as e:
            fail_count += 1
            print(f"[{idx}/{MAX_IMAGES}] âŒ å¤±è´¥ï¼š{filename} -> é”™è¯¯ï¼š{str(e)[:50]}")
            continue
    
    # 4. è¾“å‡ºçˆ¬å–ç»“æœç»Ÿè®¡
    print("\n========== çˆ¬å–å®Œæˆ ==========")
    print(f"âœ… æˆåŠŸä¸‹è½½ï¼š{success_count} å¼ ")
    print(f"âŒ ä¸‹è½½å¤±è´¥ï¼š{fail_count} å¼ ")
    print(f"ğŸ“‚ ä¿å­˜ç›®å½•ï¼š{os.path.abspath(SAVE_DIR)}")

# ================= æ‰§è¡Œçˆ¬å– =================
if __name__ == "__main__":
    # å…ˆæ£€æŸ¥CSVæ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(CSV_FILE_PATH):
        print(f"âŒ ERRORï¼šCSVæ–‡ä»¶ä¸å­˜åœ¨ï¼è·¯å¾„ï¼š{CSV_FILE_PATH}")
    else:
        crawl_book_covers()